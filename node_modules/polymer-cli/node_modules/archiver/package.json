{
  "_args": [
    [
      "archiver@https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
      "/home/diogo/www/node_modules/polymer-cli"
    ]
  ],
  "_from": "archiver@https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
  "_id": "archiver@2.1.1",
  "_inCache": true,
  "_location": "/polymer-cli/archiver",
  "_phantomChildren": {
    "lodash": "4.17.11"
  },
  "_requested": {
    "name": "archiver",
    "raw": "archiver@https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
    "rawSpec": "https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
    "scope": null,
    "spec": "https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
    "type": "remote"
  },
  "_requiredBy": [
    "/polymer-cli/wd"
  ],
  "_resolved": "https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
  "_shasum": "ff662b4a78201494a3ee544d3a33fe7496509ebc",
  "_shrinkwrap": null,
  "_spec": "archiver@https://registry.npmjs.org/archiver/-/archiver-2.1.1.tgz",
  "_where": "/home/diogo/www/node_modules/polymer-cli",
  "author": {
    "name": "Chris Talkington",
    "url": "http://christalkington.com/"
  },
  "bugs": {
    "url": "https://github.com/archiverjs/node-archiver/issues"
  },
  "dependencies": {
    "archiver-utils": "^1.3.0",
    "async": "^2.0.0",
    "buffer-crc32": "^0.2.1",
    "glob": "^7.0.0",
    "lodash": "^4.8.0",
    "readable-stream": "^2.0.0",
    "tar-stream": "^1.5.0",
    "zip-stream": "^1.2.0"
  },
  "description": "a streaming interface for archive generation",
  "devDependencies": {
    "archiver-jsdoc-theme": "^1.0.0",
    "chai": "^4.0.0",
    "jsdoc": "~3.4.0",
    "mkdirp": "^0.5.0",
    "mocha": "^3.1.1",
    "rimraf": "^2.4.2",
    "stream-bench": "^0.1.2",
    "tar": "^3.1.0",
    "yauzl": "^2.3.1"
  },
  "engines": {
    "node": ">= 4"
  },
  "files": [
    "index.js",
    "lib"
  ],
  "homepage": "https://github.com/archiverjs/node-archiver",
  "keywords": [
    "archive",
    "archiver",
    "stream",
    "tar",
    "zip"
  ],
  "license": "MIT",
  "main": "index.js",
  "name": "archiver",
  "optionalDependencies": {},
  "publishConfig": {
    "registry": "https://registry.npmjs.org/"
  },
  "readme": "# Archiver\r\n\r\n[![Build Status](https://travis-ci.org/archiverjs/node-archiver.svg?branch=master)](https://travis-ci.org/archiverjs/node-archiver) [![Build status](https://ci.appveyor.com/api/projects/status/38kqu3yp159nodxe/branch/master?svg=true)](https://ci.appveyor.com/project/ctalkington/node-archiver/branch/master)\r\n\r\na streaming interface for archive generation\r\n\r\nVisit the [API documentation](http://archiverjs.com/docs) for a list of all methods available.\r\n\r\n## Install\r\n\r\n```bash\r\nnpm install archiver --save\r\n```\r\n\r\n## Quick Start\r\n\r\n```js\r\n// require modules\r\nvar fs = require('fs');\r\nvar archiver = require('archiver');\r\n\r\n// create a file to stream archive data to.\r\nvar output = fs.createWriteStream(__dirname + '/example.zip');\r\nvar archive = archiver('zip', {\r\n  zlib: { level: 9 } // Sets the compression level.\r\n});\r\n\r\n// listen for all archive data to be written\r\n// 'close' event is fired only when a file descriptor is involved\r\noutput.on('close', function() {\r\n  console.log(archive.pointer() + ' total bytes');\r\n  console.log('archiver has been finalized and the output file descriptor has closed.');\r\n});\r\n\r\n// This event is fired when the data source is drained no matter what was the data source.\r\n// It is not part of this library but rather from the NodeJS Stream API.\r\n// @see: https://nodejs.org/api/stream.html#stream_event_end\r\noutput.on('end', function() {\r\n  console.log('Data has been drained');\r\n});\r\n\r\n// good practice to catch warnings (ie stat failures and other non-blocking errors)\r\narchive.on('warning', function(err) {\r\n  if (err.code === 'ENOENT') {\r\n    // log warning\r\n  } else {\r\n    // throw error\r\n    throw err;\r\n  }\r\n});\r\n\r\n// good practice to catch this error explicitly\r\narchive.on('error', function(err) {\r\n  throw err;\r\n});\r\n\r\n// pipe archive data to the file\r\narchive.pipe(output);\r\n\r\n// append a file from stream\r\nvar file1 = __dirname + '/file1.txt';\r\narchive.append(fs.createReadStream(file1), { name: 'file1.txt' });\r\n\r\n// append a file from string\r\narchive.append('string cheese!', { name: 'file2.txt' });\r\n\r\n// append a file from buffer\r\nvar buffer3 = Buffer.from('buff it!');\r\narchive.append(buffer3, { name: 'file3.txt' });\r\n\r\n// append a file\r\narchive.file('file1.txt', { name: 'file4.txt' });\r\n\r\n// append files from a sub-directory and naming it `new-subdir` within the archive\r\narchive.directory('subdir/', 'new-subdir');\r\n\r\n// append files from a sub-directory, putting its contents at the root of archive\r\narchive.directory('subdir/', false);\r\n\r\n// append files from a glob pattern\r\narchive.glob('subdir/*.txt');\r\n\r\n// finalize the archive (ie we are done appending files but streams have to finish yet)\r\n// 'close', 'end' or 'finish' may be fired right after calling this method so register to them beforehand\r\narchive.finalize();\r\n```\r\n\r\n## Formats\r\n\r\nArchiver ships with out of the box support for TAR and ZIP archives.\r\n\r\nYou can register additional formats with `registerFormat`.\r\n\r\n_Formats will be changing in the next few releases to implement a middleware approach._\r\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/archiverjs/node-archiver.git"
  },
  "scripts": {
    "bench": "node benchmark/simple/pack-zip.js",
    "jsdoc": "jsdoc -c jsdoc.json README.md",
    "test": "mocha --reporter dot"
  },
  "version": "2.1.1"
}
